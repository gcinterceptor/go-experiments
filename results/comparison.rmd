---
title: "GCI-Go reaches the Cloud: Experiments and simulation results"
author: "Daniel Fireman (danielfireman@gmail.com)"
date: "January, 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo=F)
knitr::opts_chunk$set(warning=F)

require(gridExtra)
require(boot)
require(dplyr)
require(stringr)
require(cowplot)
require(ggplot2)
require(Matching)

source("functions.R")

RESAMPLES <- 1000
```
# Experiment setup

* Throughput: 80
* Threads: 1
* Connections: 2
* Message size (amount of memory allocated per request): 204800
* Experiment duration: 120s
* Instance: 2cores, 1GB RAM

# Simulator Cross-Validation

*Simulator Assumptions*

* Linear Scalability
* Network latency is constant: 1ms

*Hyphotesis*

* $H_{0}$: The simulated latency is different from experimental latency for 1, 2 and 4 instances.

```{r}
al1.exp.gci <- accesslog("1i", "gci", 4)
al1.sim.gci <- rbind(
  read.csv("1i/sim_lb_gci_1.csv"),
  read.csv("1i/sim_lb_gci_2.csv"),
  read.csv("1i/sim_lb_gci_3.csv"),
  read.csv("1i/sim_lb_gci_4.csv"))
al1.sim.gci$latency <- al1.sim.gci$latency*1000

al1.sim.nogci <- rbind(
  read.csv("1i/sim_lb_nogci_1.csv"),
  read.csv("1i/sim_lb_nogci_2.csv"),
  read.csv("1i/sim_lb_nogci_3.csv"),
  read.csv("1i/sim_lb_nogci_4.csv"))
al1.sim.nogci$latency <- al1.sim.nogci$latency*1000

# Only consider latency of successfull requests.
al1.sim.gci <- filter(al1.sim.gci, done == "True")
al1.sim.nogci <- filter(al1.sim.nogci, done == "True")
al1.exp.gci <- filter(al1.exp.gci, status == 200)
```

## Graphical Comparison

*Summary*

```{r, fig.asp=0.5, fig.align="center"}
# If you don't trim the library, your computer could die trying to resample.
al1.cmp <- rbind(
  data.frame("latency"=sample(al1.sim.gci$latency, RESAMPLES), type="Simulator"),
  data.frame("latency"=sample(al1.exp.gci$request_time, RESAMPLES), type="Experiment"))

grid.arrange(
  ggplot(al1.cmp, aes(type, latency)) +
    geom_boxplot() +
    ggtitle("Summary") +
    ylab("Latency(ms)") +
    xlab("Type"),
   ggplot(al1.cmp, aes(latency, linetype=type)) +
    stat_ecdf() +
    ggtitle("ECDF") +
    xlab("Latency(ms)") +
    ylab("ECDF") +
    theme(legend.position="top"),
  ncol=2)
  
```


*95% Confidence Intervals For Median and Tail*

It is important for the simulator needs to be a good model for the median and tail latency. Thus, we
performed statistical tests at both parts of the latency distribution. We analyzed 3 parts of the tail:
90, 99, 99.9 percentile.

Confidence intervals for the median where calculated using the Wilcoxon signed (non-parametric) method. Confidence intervals at the tail where calculated using bootstrap resampling basic (1000 samples).

```{r, fig.align="center"}
ci.median <- function(x) {
  wt <- wilcox.test(sample(x, 1000), conf.level=0.95, conf.int = T)
  r <- wt$conf.int
  names(r) <- c("ymin", "ymax")
  return(r)
}

p99 <- function(x) {
  return(quantile(x, 0.99))
}

p999 <- function(x) {
  return(quantile(x, 0.999))
}

p9999 <- function(x) {
  return(quantile(x, 0.9999))
}

ci.p <- function(x, p) {
  ci.fun <- function(data, indices) {
    return(c(quantile(data[indices], c(p)), var(data)))
  }
  b <- boot(x, ci.fun, R=RESAMPLES)
  bci <- boot.ci(b)
  return(data.frame("ymin"=c(bci$basic[4]), "ymax"=c(bci$basic[5])))
}

ci.p99 <- function(x) {
  return(ci.p(x, 0.99))
}

ci.p999 <- function(x) {
  return(ci.p(x, 0.999))
}

ci.p9999 <- function(x) {
  return(ci.p(x, 0.9999))
}

grid.arrange(
  ggplot(al1.cmp, aes(type, latency)) +
    stat_summary(fun.y=median, geom="point", shape=23, size=2) +
    stat_summary(fun.data=ci.median, geom="errorbar", width=0.05) +
    ggtitle("Median") +
    ylab("Latency(ms)") +
    xlab("Type"),
  ggplot(al1.cmp, aes(type, latency)) +
    stat_summary(fun.y=p99, geom="point", shape=23, size=2) +
    stat_summary(fun.data=ci.p99, geom="errorbar", width=0.05) +
    ggtitle("99 Percentile") +
    ylab("Latency(ms)") +
    xlab("Type"),
  ggplot(al1.cmp, aes(type, latency)) +
    stat_summary(fun.y=p999, geom="point", shape=23, size=2) +
    stat_summary(fun.data=ci.p999, geom="errorbar", width=0.05) +
    ggtitle("99.9 Percentile") +
    ylab("Latency(ms)") +
    xlab("Type"),
  ggplot(al1.cmp, aes(type, latency)) +
    stat_summary(fun.y=p9999, geom="point", shape=23, size=2) +
    stat_summary(fun.data=ci.p9999, geom="errorbar", width=0.05) +
    ggtitle("99.99 Percentile") +
    ylab("Latency(ms)") +
    xlab("Type"),
  ncol=2,
  nrow=2)
```

## Hypothesis tests

Even though the ECDF looked very similar and the confidence intervals seem to intersect, the comparison of the two distribution failed in both tests: Mann-Whitney-Wilcoxon U Test and Two-sample Kolmogorov-Smirnov test (check distribution, i.e. median, variance and shape). More information about the tests in appendix.

As the comparison failed, we could not refute the null hypothesis.


```{r}
wilcox.test(sample(al1.sim.gci$latency, 30000), sample(al1.exp.gci$request_time, 30000))

ks.test(sample(al1.sim.gci$latency, 30000), sample(al1.exp.gci$request_time, 30000))
```

## We need a better understanding of the methods

I am not entirely convinced that the tests above are really meaningful. The main reason is that executing the same checks with smaller samples give us the opposite result:

```{r}
wilcox.test(sample(al1.sim.gci$latency, 50), sample(al1.exp.gci$request_time, 50))

ks.test(sample(al1.sim.gci$latency, 50), sample(al1.exp.gci$request_time, 50))
```

Digging deeper into the tests, I found out that they may not very suitable when dealing with samples that contains that many ties. In fact, our data is so densely distributed that 80% of 30.000+ values range from 20-60 (integers). I am not sure about the exact statistical implications of that, but I have the feeling that treat this data as categorical would lead to more accurate checks. For instance, using the Chi Squared Test:

```{r}
chisq.test(sample(al1.sim.gci$latency, 30000), sample(al1.exp.gci$request_time, 30000))
```

## Simulation Results

*Simulation setup*

* Number of servers: 1
* Simulation duration: 120
* workload: 80
* GCI Version: Go

```{r, fig.asp=0.5, fig.align="center"}
# If you don't trim the library, your computer could die trying to resample.
al1.cmp <- rbind(
  data.frame("latency"=sample(al1.sim.gci$latency, RESAMPLES), type="GCI ON"),
  data.frame("latency"=sample(al1.sim.nogci$latency, RESAMPLES), type="GCI OFF"))

grid.arrange(
   ggplot(al1.cmp, aes(latency, linetype=type)) +
    stat_ecdf() +
    ggtitle("ECDF") +
    xlab("Latency(ms)") +
    ylab("ECDF") +
    theme(legend.position="top")
   )

```

As you can see at ECDF above, by simulation the GCI On scenario have lose for GCI off. That's the expected result since GCI Off have lose in experimental results.     

```{r, fig.align="center"}
ci.median <- function(x) {
  wt <- wilcox.test(sample(x, 1000), conf.level=0.95, conf.int = T)
  r <- wt$conf.int
  names(r) <- c("ymin", "ymax")
  return(r)
}

p99 <- function(x) {
  return(quantile(x, 0.99))
}

p999 <- function(x) {
  return(quantile(x, 0.999))
}

p9999 <- function(x) {
  return(quantile(x, 0.9999))
}

ci.p <- function(x, p) {
  ci.fun <- function(data, indices) {
    return(c(quantile(data[indices], c(p)), var(data)))
  }
  b <- boot(x, ci.fun, R=RESAMPLES)
  bci <- boot.ci(b)
  return(data.frame("ymin"=c(bci$basic[4]), "ymax"=c(bci$basic[5])))
}

ci.p99 <- function(x) {
  return(ci.p(x, 0.99))
}

ci.p999 <- function(x) {
  return(ci.p(x, 0.999))
}

ci.p9999 <- function(x) {
  return(ci.p(x, 0.9999))
}

grid.arrange(
  ggplot(al1.cmp, aes(type, latency)) +
    stat_summary(fun.y=median, geom="point", shape=23, size=2) +
    stat_summary(fun.data=ci.median, geom="errorbar", width=0.05) +
    ggtitle("Median") +
    ylab("Latency(ms)") +
    xlab("Type"),
  ggplot(al1.cmp, aes(type, latency)) +
    stat_summary(fun.y=p99, geom="point", shape=23, size=2) +
    stat_summary(fun.data=ci.p99, geom="errorbar", width=0.05) +
    ggtitle("99 Percentile") +
    ylab("Latency(ms)") +
    xlab("Type"),
  ggplot(al1.cmp, aes(type, latency)) +
    stat_summary(fun.y=p999, geom="point", shape=23, size=2) +
    stat_summary(fun.data=ci.p999, geom="errorbar", width=0.05) +
    ggtitle("99.9 Percentile") +
    ylab("Latency(ms)") +
    xlab("Type"),
  ggplot(al1.cmp, aes(type, latency)) +
    stat_summary(fun.y=p9999, geom="point", shape=23, size=2) +
    stat_summary(fun.data=ci.p9999, geom="errorbar", width=0.05) +
    ggtitle("99.99 Percentile") +
    ylab("Latency(ms)") +
    xlab("Type"),
  ncol=2,
  nrow=2)

```

But, as shown at the plots of interval coefficient (IC) above, the percentile 99.99 have take a promising result. Again, that was the expected result since at experimental result it have happen.


# Appendix

## Simulator

*Inputs*

* The number of server instances to simulate.
* A simulation duration.
* A scenario. The simulator recognizes control and baseline scenarios. Control and Baseline means servers with gci and servers with no gci, respectively. 
* The workload to be simulated at load balancer.    
* A path where the simulator should put its results and a path where the experimental data is. 
* The name of the file with the experimental data log and the column number related with request latency. 
* A simulation ID to identify the simulation.
* The name of the shedding log (when scenario is control).
* How many shedding logs exist (when scenario is control).

*Assumptions*

* The load balancer sends all requests to each server known in a perfect distribution.
* The comunication time of load balancer and server is one millisecond.
* To model the time that a request stay at a server, choose some value randomly from a experimental log may be enough.
* To model the GCI behavior, reproduce how many requests were processed until GCI start shedding and reproduce how many requests should be shedded until GCI stop shedding may be enough.

*Output*

* The time when each request saved was created. A request saved is a request that has been already finished or lost.
* The latency of each request saved.
* The time between be accepted in a server and returned to a load balancer of each request.
* If each request was done or not. It means if the request was processed in some server or refused on all.
* How many times each request was fowarded to a server.
* How many requests were created, shedded, refused and lost.

## Kolmogorov-Smirnov Two-Sample Test

The Kolmogorov–Smirnov statistic quantifies a distance between distribution functions of two samples. The null distribution of this statistic is calculated under the null hypothesis that the samples are drawn from the same distribution (in the two-sample case). In each case, the distributions considered under the null hypothesis are continuous distributions but are otherwise unrestricted.

The two-sample K–S test is one of the most useful and general nonparametric methods for comparing two samples, as it is sensitive to differences in both location and shape of the empirical cumulative distribution functions of the two samples [Wikipedia](https://en.wikipedia.org/wiki/Kolmogorov%E2%80%93Smirnov_test).

More references:

* [KS Test in R](https://stats.stackexchange.com/questions/222294/understanding-kolmogorov-smirnov-test-in-r)

* [KS Test in discrete variables](https://stats.stackexchange.com/questions/48317/kolmogorov-smirnov-with-discrete-data-what-is-proper-use-of-dgofks-test-in-r)

* [KS Test](https://onlinecourses.science.psu.edu/stat414/node/234)

* [KS Test](http://www.physics.csbsju.edu/stats/KS-test.html)

## Two-sample Mann–Whitney U Test

Two data samples are independent if they come from distinct populations and the samples do not affect each other. Using the Mann-Whitney-Wilcoxon Test, we can decide whether the population distributions are identical without assuming them to follow the normal distribution.

More references:

* [Two-sample Mann–Whitney U Test](http://rcompanion.org/handbook/F_04.html)

* [Wikipedia](https://en.wikipedia.org/wiki/Mann%E2%80%93Whitney_U_test)

* [R-Tutors](http://www.r-tutor.com/elementary-statistics/non-parametric-methods/mann-whitney-wilcoxon-test)