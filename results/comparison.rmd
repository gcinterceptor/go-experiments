---
title: "GCI-Go reaches the Cloud: Experiments and simulation results"
author: "Daniel Fireman (danielfireman@gmail.com)"
date: "January, 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo=F)
knitr::opts_chunk$set(warning=F)

require(gridExtra)
require(boot)
require(dplyr)
require(stringr)
require(cowplot)

source("functions.R")
```
# Experiment setup

* Throughput: 80
* Threads: 1
* Connections: 2
* Message size (amount of memory allocated per request): 204800
* Experiment duration: 120s
* Instance: 2cores, 1GB RAM

# Simulator Cross-Validation

*Simulator Assumptions*

* Linear Scalability
* Network latency is constant: 1ms

*Hyphotesis*

* $H_{0}$: The simulated latency is different from experimental latency for 1, 2 and 4 instances.

```{r}
al1.exp.gci <- accesslog("1i", "gci", 4)
al1.sim.gci <- rbind(
  read.csv("1i/sim_lb_gci_1.csv"),
  read.csv("1i/sim_lb_gci_2.csv"),
  read.csv("1i/sim_lb_gci_3.csv"),
  read.csv("1i/sim_lb_gci_4.csv"))

# Only consider latency of successfull requests.
al1.sim.gci <- filter(al1.sim.gci, done == "True")
al1.exp.gci <- filter(al1.exp.gci, status == 200)
```


```{r plots}
al1.cmp <- rbind(
  data.frame("latency"=al1.sim.gci$service_time*1000, type="Simulator"),
  data.frame("latency"=al1.exp.gci$request_time, type="Experiment"))

ggplot(al1.cmp, aes(type, latency)) +
  geom_boxplot() +
  ggtitle("Median") +
  ylab("Latency(ms)") +
  xlab("Type")
```

# Simulation Results



# Appendix

## Simulator

*Inputs*

* The number of server instances to simulate.
* A simulation duration.
* A scenario. The simulator recognizes control and baseline scenarios. Control and Baseline means servers with gci and servers with no gci, respectively. 
* The workload to be simulated at load balancer.    
* A path where the simulator should put its results and a path where the experimental data is. 
* The name of the file with the experimental data log and the column number related with request latency. 
* A simulation ID to identify the simulation.
* The name of the shedding log (when scenario is control).
* How many shedding logs exist (when scenario is control).

*Assumptions*

* The load balancer sends all requests to each server known in a perfect distribution.
* The comunication time of load balancer and server is one millisecond.
* To model the time that a request stay at a server, choosing some value randomly from a experimental log may be enough.
* To model the GCI behavior, reproduce how many requests were processed until GCI start shedding and reproduce how many requests should be shedded until GCI stop shedding may be enough.


*Output*

* The time when each request saved was created. A request saved is a request that has been already finished or lost.
* The latency of each request saved.
* The time between be accepted in a server and returned to a load balancer of each request.
* If each request was done or not. It means if the request was processed in some server or refused on all.
* How many times each request was fowarded to a server.
* How many requests were created, shedded, refused and lost.

