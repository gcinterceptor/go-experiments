---
title: "GCI-Go reaches the Cloud: Experiments and simulation results"
author: "Daniel Fireman (danielfireman@gmail.com)"
date: "January, 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo=F)
knitr::opts_chunk$set(warning=F)

require(gridExtra)
require(boot)
require(dplyr)
require(stringr)
require(cowplot)

source("functions.R")

RESAMPLES <- 1000
```
# Experiment setup

* Throughput: 80
* Threads: 1
* Connections: 2
* Message size (amount of memory allocated per request): 204800
* Experiment duration: 120s
* Instance: 2cores, 1GB RAM

# Simulator Cross-Validation

*Simulator Assumptions*

* Linear Scalability
* Network latency is constant: 1ms

*Hyphotesis*

* $H_{0}$: The simulated latency is different from experimental latency for 1, 2 and 4 instances.

```{r}
al1.exp.gci <- accesslog("1i", "gci", 4)
al1.sim.gci <- rbind(
  read.csv("1i/sim_lb_gci_1.csv"),
  read.csv("1i/sim_lb_gci_2.csv"),
  read.csv("1i/sim_lb_gci_3.csv"),
  read.csv("1i/sim_lb_gci_4.csv"))

# Only consider latency of successfull requests.
al1.sim.gci <- filter(al1.sim.gci, done == "True")
al1.exp.gci <- filter(al1.exp.gci, status == 200)
```

## Graphical Comparison

*Summary*

```{r, fig.asp=0.5, fig.align="center"}
# If you don't trim the library, your computer could die trying to resample.
al1.cmp <- rbind(
  data.frame("latency"=sample(al1.sim.gci$service_time*1000, RESAMPLES), type="Simulator"),
  data.frame("latency"=sample(al1.exp.gci$request_time, RESAMPLES), type="Experiment"))

ggplot(al1.cmp, aes(type, latency)) +
  geom_boxplot() +
  ggtitle("Summary") +
  ylab("Latency(ms)") +
  xlab("Type")
```


*95% Confidence Intervals For Median and Tail*

It is important for the simulator needs to be a good model for the median and tail latency. Thus, we
performed statistical tests at both parts of the latency distribution. We analyzed 3 parts of the tail:
90, 99, 99.9 percentile.

Confidence intervals for the median where calculated using the Wilcoxon signed (non-parametric) method. Confidence intervals at the tail where calculated using bootstrap resampling basic (1000 samples).

```{r, fig.align="center"}
ci.median <- function(x) {
  wt <- wilcox.test(sample(x, 1000), conf.level=0.95, conf.int = T)
  r <- wt$conf.int
  names(r) <- c("ymin", "ymax")
  return(r)
}

p99 <- function(x) {
  return(quantile(x, 0.99))
}

p999 <- function(x) {
  return(quantile(x, 0.999))
}

p9999 <- function(x) {
  return(quantile(x, 0.9999))
}

ci.p <- function(x, p) {
  ci.fun <- function(data, indices) {
    return(c(quantile(data[indices], c(p)), var(data)))
  }
  b <- boot(x, ci.fun, R=RESAMPLES)
  bci <- boot.ci(b)
  return(data.frame("ymin"=c(bci$basic[4]), "ymax"=c(bci$basic[5])))
}

ci.p99 <- function(x) {
  return(ci.p(x, 0.99))
}

ci.p999 <- function(x) {
  return(ci.p(x, 0.999))
}

ci.p9999 <- function(x) {
  return(ci.p(x, 0.9999))
}

grid.arrange(
  ggplot(al1.cmp, aes(type, latency)) +
    stat_summary(fun.y=median, geom="point", shape=23, size=2) +
    stat_summary(fun.data=ci.median, geom="errorbar", width=0.05) +
    ggtitle("Median") +
    ylab("Latency(ms)") +
    xlab("Type"),
  ggplot(al1.cmp, aes(type, latency)) +
    stat_summary(fun.y=p99, geom="point", shape=23, size=2) +
    stat_summary(fun.data=ci.p99, geom="errorbar", width=0.05) +
    ggtitle("99 Percentile") +
    ylab("Latency(ms)") +
    xlab("Type"),
  ggplot(al1.cmp, aes(type, latency)) +
    stat_summary(fun.y=p999, geom="point", shape=23, size=2) +
    stat_summary(fun.data=ci.p999, geom="errorbar", width=0.05) +
    ggtitle("99.9 Percentile") +
    ylab("Latency(ms)") +
    xlab("Type"),
  ggplot(al1.cmp, aes(type, latency)) +
    stat_summary(fun.y=p9999, geom="point", shape=23, size=2) +
    stat_summary(fun.data=ci.p9999, geom="errorbar", width=0.05) +
    ggtitle("99.99 Percentile") +
    ylab("Latency(ms)") +
    xlab("Type"),
  ncol=2,
  nrow=2)
```

# Simulation Results

# Appendix

## Simulator

*Inputs*

* The number of server instances to simulate.
* A simulation duration.
* A scenario. The simulator recognizes control and baseline scenarios. Control and Baseline means servers with gci and servers with no gci, respectively. 
* The workload to be simulated at load balancer.    
* A path where the simulator should put its results and a path where the experimental data is. 
* The name of the file with the experimental data log and the column number related with request latency. 
* A simulation ID to identify the simulation.
* The name of the shedding log (when scenario is control).
* How many shedding logs exist (when scenario is control).

*Assumptions*

* The load balancer sends all requests to each server known in a perfect distribution.
* The comunication time of load balancer and server is one millisecond.
* To model the time that a request stay at a server, choose some value randomly from a experimental log may be enough.
* To model the GCI behavior, reproduce how many requests were processed until GCI start shedding and reproduce how many requests should be shedded until GCI stop shedding may be enough.

*Output*

* The time when each request saved was created. A request saved is a request that has been already finished or lost.
* The latency of each request saved.
* The time between be accepted in a server and returned to a load balancer of each request.
* If each request was done or not. It means if the request was processed in some server or refused on all.
* How many times each request was fowarded to a server.
* How many requests were created, shedded, refused and lost.

